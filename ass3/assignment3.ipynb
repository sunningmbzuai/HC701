{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "sublime-accuracy",
   "metadata": {
    "papermill": {
     "duration": 0.008555,
     "end_time": "2021-04-06T12:51:07.051470",
     "exception": false,
     "start_time": "2021-04-06T12:51:07.042915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Assignment3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "favorite-tunnel",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-04-06T12:51:07.072611Z",
     "iopub.status.busy": "2021-04-06T12:51:07.070920Z",
     "iopub.status.idle": "2021-04-06T12:51:20.714935Z",
     "shell.execute_reply": "2021-04-06T12:51:20.716096Z"
    },
    "papermill": {
     "duration": 13.656978,
     "end_time": "2021-04-06T12:51:20.716513",
     "exception": false,
     "start_time": "2021-04-06T12:51:07.059535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "    \n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "coordinated-child",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-04-06T12:51:20.751989Z",
     "iopub.status.busy": "2021-04-06T12:51:20.751246Z",
     "iopub.status.idle": "2021-04-06T12:51:21.517321Z",
     "shell.execute_reply": "2021-04-06T12:51:21.516667Z"
    },
    "papermill": {
     "duration": 0.785733,
     "end_time": "2021-04-06T12:51:21.517478",
     "exception": false,
     "start_time": "2021-04-06T12:51:20.731745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>liver_maskpath</th>\n",
       "      <th>tumor_maskpath</th>\n",
       "      <th>study_number</th>\n",
       "      <th>instance_number</th>\n",
       "      <th>liver_mask_empty</th>\n",
       "      <th>tumor_mask_empty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>lits-png/volume-2_440.png</td>\n",
       "      <td>lits-png/segmentation-2_livermask_440.png</td>\n",
       "      <td>lits-png/segmentation-2_lesionmask_440.png</td>\n",
       "      <td>2</td>\n",
       "      <td>184</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>lits-png/volume-2_441.png</td>\n",
       "      <td>lits-png/segmentation-2_livermask_441.png</td>\n",
       "      <td>lits-png/segmentation-2_lesionmask_441.png</td>\n",
       "      <td>2</td>\n",
       "      <td>185</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>lits-png/volume-2_442.png</td>\n",
       "      <td>lits-png/segmentation-2_livermask_442.png</td>\n",
       "      <td>lits-png/segmentation-2_lesionmask_442.png</td>\n",
       "      <td>2</td>\n",
       "      <td>186</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>lits-png/volume-2_443.png</td>\n",
       "      <td>lits-png/segmentation-2_livermask_443.png</td>\n",
       "      <td>lits-png/segmentation-2_lesionmask_443.png</td>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>lits-png/volume-2_444.png</td>\n",
       "      <td>lits-png/segmentation-2_livermask_444.png</td>\n",
       "      <td>lits-png/segmentation-2_lesionmask_444.png</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37935</th>\n",
       "      <td>lits-png/volume-125_216.png</td>\n",
       "      <td>lits-png/segmentation-125_livermask_216.png</td>\n",
       "      <td>lits-png/segmentation-125_lesionmask_216.png</td>\n",
       "      <td>125</td>\n",
       "      <td>216</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37936</th>\n",
       "      <td>lits-png/volume-125_217.png</td>\n",
       "      <td>lits-png/segmentation-125_livermask_217.png</td>\n",
       "      <td>lits-png/segmentation-125_lesionmask_217.png</td>\n",
       "      <td>125</td>\n",
       "      <td>217</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37937</th>\n",
       "      <td>lits-png/volume-125_218.png</td>\n",
       "      <td>lits-png/segmentation-125_livermask_218.png</td>\n",
       "      <td>lits-png/segmentation-125_lesionmask_218.png</td>\n",
       "      <td>125</td>\n",
       "      <td>218</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37938</th>\n",
       "      <td>lits-png/volume-125_219.png</td>\n",
       "      <td>lits-png/segmentation-125_livermask_219.png</td>\n",
       "      <td>lits-png/segmentation-125_lesionmask_219.png</td>\n",
       "      <td>125</td>\n",
       "      <td>219</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37939</th>\n",
       "      <td>lits-png/volume-125_220.png</td>\n",
       "      <td>lits-png/segmentation-125_livermask_220.png</td>\n",
       "      <td>lits-png/segmentation-125_lesionmask_220.png</td>\n",
       "      <td>125</td>\n",
       "      <td>220</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4132 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filepath  \\\n",
       "374      lits-png/volume-2_440.png   \n",
       "376      lits-png/volume-2_441.png   \n",
       "378      lits-png/volume-2_442.png   \n",
       "380      lits-png/volume-2_443.png   \n",
       "382      lits-png/volume-2_444.png   \n",
       "...                            ...   \n",
       "37935  lits-png/volume-125_216.png   \n",
       "37936  lits-png/volume-125_217.png   \n",
       "37937  lits-png/volume-125_218.png   \n",
       "37938  lits-png/volume-125_219.png   \n",
       "37939  lits-png/volume-125_220.png   \n",
       "\n",
       "                                    liver_maskpath  \\\n",
       "374      lits-png/segmentation-2_livermask_440.png   \n",
       "376      lits-png/segmentation-2_livermask_441.png   \n",
       "378      lits-png/segmentation-2_livermask_442.png   \n",
       "380      lits-png/segmentation-2_livermask_443.png   \n",
       "382      lits-png/segmentation-2_livermask_444.png   \n",
       "...                                            ...   \n",
       "37935  lits-png/segmentation-125_livermask_216.png   \n",
       "37936  lits-png/segmentation-125_livermask_217.png   \n",
       "37937  lits-png/segmentation-125_livermask_218.png   \n",
       "37938  lits-png/segmentation-125_livermask_219.png   \n",
       "37939  lits-png/segmentation-125_livermask_220.png   \n",
       "\n",
       "                                     tumor_maskpath  study_number  \\\n",
       "374      lits-png/segmentation-2_lesionmask_440.png             2   \n",
       "376      lits-png/segmentation-2_lesionmask_441.png             2   \n",
       "378      lits-png/segmentation-2_lesionmask_442.png             2   \n",
       "380      lits-png/segmentation-2_lesionmask_443.png             2   \n",
       "382      lits-png/segmentation-2_lesionmask_444.png             2   \n",
       "...                                             ...           ...   \n",
       "37935  lits-png/segmentation-125_lesionmask_216.png           125   \n",
       "37936  lits-png/segmentation-125_lesionmask_217.png           125   \n",
       "37937  lits-png/segmentation-125_lesionmask_218.png           125   \n",
       "37938  lits-png/segmentation-125_lesionmask_219.png           125   \n",
       "37939  lits-png/segmentation-125_lesionmask_220.png           125   \n",
       "\n",
       "       instance_number  liver_mask_empty  tumor_mask_empty  \n",
       "374                184              True              True  \n",
       "376                185              True              True  \n",
       "378                186              True              True  \n",
       "380                187              True              True  \n",
       "382                188              True              True  \n",
       "...                ...               ...               ...  \n",
       "37935              216              True              True  \n",
       "37936              217              True              True  \n",
       "37937              218              True              True  \n",
       "37938              219              True              True  \n",
       "37939              220              True              True  \n",
       "\n",
       "[4132 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### preprocess data\n",
    "\n",
    "train_csv = \"/apps/local/shared/HC701/assessment/assignment_3/data/hc701_lits_train.csv\"\n",
    "test_csv = \"/apps/local/shared/HC701/assessment/assignment_3/data/hc701_lits_test.csv\"\n",
    "data_root = \"/apps/local/shared/HC701/assessment/assignment_3/data\"\n",
    "\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_csv)\n",
    "\n",
    "# only load data with both mask\n",
    "train_data = train_df[(train_df['tumor_mask_empty']==True) & (train_df['liver_mask_empty']==True)]\n",
    "test_data = test_df[(test_df['tumor_mask_empty']==True) & (test_df['liver_mask_empty']==True)]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "proper-austin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-06T12:51:21.546848Z",
     "iopub.status.busy": "2021-04-06T12:51:21.545003Z",
     "iopub.status.idle": "2021-04-06T12:51:21.547597Z",
     "shell.execute_reply": "2021-04-06T12:51:21.547987Z"
    },
    "papermill": {
     "duration": 0.020615,
     "end_time": "2021-04-06T12:51:21.548116",
     "exception": false,
     "start_time": "2021-04-06T12:51:21.527501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConsecutiveConvolution(nn.Module):\n",
    "    def __init__(self,input_channel,out_channel):\n",
    "        super(ConsecutiveConvolution,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(input_channel,out_channel,3,1,1,bias=False),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(out_channel,out_channel,3,1,1,bias=False),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU6(inplace=True),            \n",
    "        \n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "liked-equilibrium",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-06T12:51:21.582594Z",
     "iopub.status.busy": "2021-04-06T12:51:21.580567Z",
     "iopub.status.idle": "2021-04-06T12:51:21.583268Z",
     "shell.execute_reply": "2021-04-06T12:51:21.583733Z"
    },
    "papermill": {
     "duration": 0.025967,
     "end_time": "2021-04-06T12:51:21.583884",
     "exception": false,
     "start_time": "2021-04-06T12:51:21.557917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self,input_channel, output_channel, features = [64,128,256,512]):\n",
    "        super(UNet,self).__init__()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "\n",
    "        # initialize the encoder\n",
    "        for feat in features:\n",
    "            self.encoder.append(\n",
    "                ConsecutiveConvolution(input_channel, feat)    \n",
    "            )\n",
    "            input_channel = feat\n",
    "        \n",
    "        #initialize the decoder \n",
    "        for feat in reversed(features):\n",
    "            # the authors used transpose convolution\n",
    "            self.decoder.append(nn.ConvTranspose2d(feat*2, feat, kernel_size=2, stride=2))\n",
    "            self.decoder.append(ConsecutiveConvolution(feat*2, feat))\n",
    "        \n",
    "        #bottleneck\n",
    "        self.bottleneck = ConsecutiveConvolution(features[-1],features[-1]*2)\n",
    "        \n",
    "        #output layer\n",
    "        self.final_layer = nn.Conv2d(features[0],output_channel,kernel_size=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        skip_connections = []\n",
    "        \n",
    "        #encoding\n",
    "        for layers in self.encoder:\n",
    "            x = layers(x)\n",
    "            #skip connection to be used in recreation \n",
    "            skip_connections.append(x)\n",
    "\n",
    "            x = self.pool(x)\n",
    "        \n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        skip_connections = skip_connections[::-1]\n",
    "        \n",
    "        \n",
    "        for idx in range(0,len(self.decoder),2):\n",
    "            \n",
    "            \n",
    "            x = self.decoder[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "            \n",
    "    \n",
    "            if x.shape != skip_connection.shape[2:]:\n",
    "                x = TF.resize(x,size=skip_connection.shape[2:])\n",
    "            \n",
    "            concat_skip = torch.cat((skip_connection,x),dim=1)\n",
    "#             print(concat_skip.shape)\n",
    "#             print(self.decoder[idx+1])\n",
    "\n",
    "            x = self.decoder[idx+1](concat_skip)\n",
    "        \n",
    "        return self.final_layer(x)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "coated-consequence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-06T12:51:21.617974Z",
     "iopub.status.busy": "2021-04-06T12:51:21.616355Z",
     "iopub.status.idle": "2021-04-06T12:51:21.618556Z",
     "shell.execute_reply": "2021-04-06T12:51:21.619017Z"
    },
    "papermill": {
     "duration": 0.025316,
     "end_time": "2021-04-06T12:51:21.619185",
     "exception": false,
     "start_time": "2021-04-06T12:51:21.593869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CXRDataset(Dataset):\n",
    "    def __init__(self, image_list, liver_mask_list,tumor_mask_list,img_root,split=None,transform=None):\n",
    "        self.image_list = image_list\n",
    "        self.liver_mask_list = liver_mask_list\n",
    "        self.tumor_mask_list = tumor_mask_list\n",
    "        self.transform = transform\n",
    "        self.img_root = img_root\n",
    "        # split validate dataset from train dataset\n",
    "        if split == 'train':\n",
    "            total_len = len(self.image_list)\n",
    "            self.image_list = self.image_list[:int(0.8*total_len)]\n",
    "            self.liver_mask_list = self.liver_mask_list[:int(0.8*total_len)]\n",
    "            self.tumor_mask_list = self.tumor_mask_list[:int(0.8*total_len)]\n",
    "        elif split == 'val':\n",
    "            total_len = len(self.image_list)\n",
    "            self.image_list = self.image_list[int(0.8*total_len):]\n",
    "            self.liver_mask_list = self.liver_mask_list[int(0.8*total_len):]\n",
    "            self.tumor_mask_list = self.tumor_mask_list[int(0.8*total_len):]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        liver_mask_path = os.path.join(self.img_root, self.liver_mask_list[index])\n",
    "        tumor_mask_path = os.path.join(self.img_root, self.tumor_mask_list[index])\n",
    "        img_path = os.path.join(self.img_root, self.image_list[index])\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        liver_mask = np.array(Image.open(liver_mask_path).convert(\"L\"), dtype=np.float32)\n",
    "        tumor_mask = np.array(Image.open(tumor_mask_path).convert(\"L\"), dtype=np.float32)\n",
    "        liver_mask[liver_mask == 255.0] = 1.0\n",
    "        tumor_mask[tumor_mask == 255.0] = 1.0\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmentations = self.transform(image=image, liver_mask=liver_mask, tumor_mask=tumor_mask)\n",
    "            image = augmentations[\"image\"]\n",
    "            liver_mask = augmentations[\"liver_mask\"]\n",
    "            tumor_mask = augmentations[\"tumor_mask\"]\n",
    "\n",
    "        return image, liver_mask, tumor_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "serious-blond",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-06T12:51:21.655554Z",
     "iopub.status.busy": "2021-04-06T12:51:21.653537Z",
     "iopub.status.idle": "2021-04-06T12:51:21.656309Z",
     "shell.execute_reply": "2021-04-06T12:51:21.656943Z"
    },
    "papermill": {
     "duration": 0.028435,
     "end_time": "2021-04-06T12:51:21.657140",
     "exception": false,
     "start_time": "2021-04-06T12:51:21.628705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(checkpoint, model):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "def get_loaders(\n",
    "    train_data,\n",
    "    test_data,\n",
    "    data_root,\n",
    "    batch_size,\n",
    "    train_transform,\n",
    "    val_transform,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,):\n",
    "    \n",
    "    \n",
    "    train_ds = CXRDataset(\n",
    "        image_list=train_data['filepath'].tolist(), \n",
    "        liver_mask_list=train_data['liver_maskpath'].tolist(),\n",
    "        tumor_mask_list=train_data['tumor_maskpath'].tolist(),\n",
    "        img_root=data_root,\n",
    "        split='train',\n",
    "        transform=train_transform,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_ds = CXRDataset(\n",
    "        image_list=train_data['filepath'].tolist(), \n",
    "        liver_mask_list=train_data['liver_maskpath'].tolist(),\n",
    "        tumor_mask_list=train_data['tumor_maskpath'].tolist(),\n",
    "        img_root=data_root,\n",
    "        split='val',\n",
    "        transform=train_transform,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    test_ds = CXRDataset(\n",
    "        image_list=test_data['filepath'].tolist(), \n",
    "        liver_mask_list=test_data['liver_maskpath'].tolist(),\n",
    "        tumor_mask_list=test_data['tumor_maskpath'].tolist(),\n",
    "        img_root=data_root,\n",
    "        transform=val_transform,\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "SMOOTH = 1e-6\n",
    "def IOU(outputs: torch.Tensor, labels: torch.Tensor):\n",
    "    # You can comment out this line if you are passing tensors of equal shape\n",
    "    # But if you are passing output from UNet or something it will most probably\n",
    "    # be with the BATCH x 1 x H x W shape\n",
    "    outputs = outputs.squeeze(1)  # BATCH x 1 x H x W => BATCH x H x W\n",
    "    \n",
    "    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n",
    "    union = (outputs | labels).float().sum((1, 2))         # Will be zzero if both are 0\n",
    "    \n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)  # We smooth our devision to avoid 0/0\n",
    "    \n",
    "    thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds\n",
    "    \n",
    "    return thresholded\n",
    "\n",
    "def val_fn(loader, model, device=\"cuda\",epoch=0):\n",
    "    liver_num_correct = 0\n",
    "    tumor_num_correct = 0\n",
    "    liver_num_pixels = 0\n",
    "    tumor_num_pixels = 0\n",
    "    liver_dice_score = 0\n",
    "    tumor_dice_score=0\n",
    "    liver_iou = 0\n",
    "    tumor_iou = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y1,y2 in loader:\n",
    "            x = x.to(device)\n",
    "            y1 = y1.to(device).unsqueeze(1)\n",
    "            y2 = y2.to(device).unsqueeze(1)\n",
    "            preds = model(x)\n",
    "            preds1 = (torch.sigmoid(preds[:,0]) > 0.5).float()\n",
    "            preds2 = (torch.sigmoid(preds[:,1]) > 0.5).float()\n",
    "            liver_num_correct += (preds1 == y1).sum()\n",
    "            tumor_num_correct += (preds2 == y2).sum()\n",
    "            liver_num_pixels += torch.numel(preds1)\n",
    "            tumor_num_pixels += torch.numel(preds2)\n",
    "            liver_dice_score += (2 * (preds1 * y1).sum()) / (\n",
    "                (preds1 + y1).sum() + 1e-8\n",
    "            )\n",
    "            tumor_dice_score += (2 * (preds2 * y2).sum()) / (\n",
    "                (preds2 + y2).sum() + 1e-8\n",
    "            )\n",
    "            liver_iou += IOU(preds1,y1)\n",
    "            tumor_iou += IOU(preds2,y2)\n",
    "\n",
    "    wandb.log({\"liver acc\": liver_num_correct/liver_num_pixels*100,\n",
    "               \"liver Dice\":liver_dice_score/len(loader),\n",
    "               \"tumor acc\":tumor_num_correct/tumor_num_pixels*100,\n",
    "               \"tumor Dice\":tumor_dice_score/len(loader),\n",
    "               \"liver IOU\": liver_iou/len(loader),\n",
    "               \"tumor IOU\": tumor_iou/len(loader),\n",
    "               'epoch':epoch})\n",
    " \n",
    "\n",
    "# def save_predictions_as_imgs(loader, model, folder=\"saved_images/\", device=\"cuda\"):\n",
    "    \n",
    "#     model.eval()\n",
    "#     for idx, (x, y1, y2) in enumerate(loader):\n",
    "#         x = x.to(device=device)\n",
    "#         with torch.no_grad():\n",
    "#             preds1,preds2 = torch.sigmoid(model(x))\n",
    "#             preds = (preds > 0.5).float()\n",
    "#         torchvision.utils.save_image(\n",
    "#             preds, f\"{folder}/pred_{idx}.png\"\n",
    "#         )\n",
    "#         torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}{idx}.png\")\n",
    "\n",
    "#     model.train()\n",
    "\n",
    "def test_fn(loader, model, device=\"cuda\",epoch=0):\n",
    "    model.eval()\n",
    "    liver_num_correct = 0\n",
    "    tumor_num_correct = 0\n",
    "    liver_num_pixels = 0\n",
    "    tumor_num_pixels = 0\n",
    "    liver_dice_score = 0\n",
    "    tumor_dice_score=0\n",
    "    liver_iou = 0\n",
    "    tumor_iou = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y1,y2 in loader:\n",
    "            x = x.to(device)\n",
    "            y1 = y1.to(device).unsqueeze(1)\n",
    "            y2 = y2.to(device).unsqueeze(1)\n",
    "            preds = model(x)\n",
    "            preds1 = (torch.sigmoid(preds[:,0]) > 0.5).float()\n",
    "            preds2 = (torch.sigmoid(preds[:,1]) > 0.5).float()\n",
    "            liver_num_correct += (preds1 == y1).sum()\n",
    "            tumor_num_correct += (preds2 == y2).sum()\n",
    "            liver_num_pixels += torch.numel(preds1)\n",
    "            tumor_num_pixels += torch.numel(preds2)\n",
    "            liver_dice_score += (2 * (preds1 * y1).sum()) / (\n",
    "                (preds1 + y1).sum() + 1e-8\n",
    "            )\n",
    "            tumor_dice_score += (2 * (preds2 * y2).sum()) / (\n",
    "                (preds2 + y2).sum() + 1e-8\n",
    "            )\n",
    "            liver_iou += IOU(preds1,y1)\n",
    "            tumor_iou += IOU(preds2,y2)\n",
    "\n",
    "    wandb.log({\"liver Dice\":liver_dice_score/len(loader),\n",
    "               \"tumor Dice\":tumor_dice_score/len(loader),\n",
    "               \"liver Jaccard\": liver_iou/len(loader),\n",
    "               \"tumor Jaccard\": tumor_iou/len(loader),\n",
    "               'epoch':epoch})\n",
    "    model.train()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "latest-devil",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-06T12:51:21.683026Z",
     "iopub.status.busy": "2021-04-06T12:51:21.681160Z",
     "iopub.status.idle": "2021-04-06T12:51:21.683597Z",
     "shell.execute_reply": "2021-04-06T12:51:21.684017Z"
    },
    "papermill": {
     "duration": 0.01745,
     "end_time": "2021-04-06T12:51:21.684168",
     "exception": false,
     "start_time": "2021-04-06T12:51:21.666718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "lr = 1e-4\n",
    "dev = \"cuda\"\n",
    "batch_size = 8\n",
    "epochs = 50\n",
    "workers= 8\n",
    "img_h = 256\n",
    "img_w = 256\n",
    "pin_mem= True\n",
    "load_model = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "defensive-heading",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-06T12:51:21.712883Z",
     "iopub.status.busy": "2021-04-06T12:51:21.710884Z",
     "iopub.status.idle": "2021-04-06T12:51:21.713492Z",
     "shell.execute_reply": "2021-04-06T12:51:21.713913Z"
    },
    "papermill": {
     "duration": 0.019925,
     "end_time": "2021-04-06T12:51:21.714048",
     "exception": false,
     "start_time": "2021-04-06T12:51:21.694123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "    model.train()\n",
    "    loop = tqdm(loader)\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, targets1,targets2) in enumerate(loop):\n",
    "        data = data.to(device=dev)\n",
    "        targets1 = targets1.float().unsqueeze(1).to(device=dev)\n",
    "        targets2 = targets2.float().unsqueeze(1).to(device=dev)\n",
    "\n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)\n",
    "            loss1 = loss_fn(predictions[:,0].view(targets1.size), targets1)\n",
    "            loss2 = loss_fn(predictions[:,1].view(targets2.size), targets2)\n",
    "            loss = loss1 + loss2\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # update tqdm loop\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    wandb.log({\"train_loss\": train_loss/(batch_idx+1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "religious-cause",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-06T12:51:21.748520Z",
     "iopub.status.busy": "2021-04-06T12:51:21.743088Z",
     "iopub.status.idle": "2021-04-06T13:23:25.415917Z",
     "shell.execute_reply": "2021-04-06T13:23:25.415330Z"
    },
    "papermill": {
     "duration": 1923.690808,
     "end_time": "2021-04-06T13:23:25.416069",
     "exception": false,
     "start_time": "2021-04-06T12:51:21.725261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:88ltq8kb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">true-sponge-3</strong> at: <a href='https://wandb.ai/sunning/hc_assign3_exp1/runs/88ltq8kb' target=\"_blank\">https://wandb.ai/sunning/hc_assign3_exp1/runs/88ltq8kb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_210032-88ltq8kb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:88ltq8kb). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eafd452795144b3aeda0d5ccb8b0fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016670700954273344, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ning.sun/Documents/HC701/assignment/HC701/ass3/wandb/run-20230331_210057-up4biben</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sunning/hc_assign3_exp1/runs/up4biben' target=\"_blank\">light-blaze-4</a></strong> to <a href='https://wandb.ai/sunning/hc_assign3_exp1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sunning/hc_assign3_exp1' target=\"_blank\">https://wandb.ai/sunning/hc_assign3_exp1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sunning/hc_assign3_exp1/runs/up4biben' target=\"_blank\">https://wandb.ai/sunning/hc_assign3_exp1/runs/up4biben</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2585 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "  0%|          | 0/2585 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 23.64 GiB total capacity; 4.71 GiB already allocated; 52.81 MiB free; 4.74 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39mprint\u001b[39m(epoch)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m     train_fn(train_loader, model, optimizer, loss_fn, scaler)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39m# save model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     checkpoint \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m\"\u001b[39m: model\u001b[39m.\u001b[39mstate_dict(),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m\"\u001b[39m:optimizer\u001b[39m.\u001b[39mstate_dict(),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m     }\n",
      "\u001b[1;32m/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb Cell 10\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(loader, model, optimizer, loss_fn, scaler)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# forward\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast():\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     predictions \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     loss1 \u001b[39m=\u001b[39m loss_fn(predictions[:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mview(targets1\u001b[39m.\u001b[39msize), targets1)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     loss2 \u001b[39m=\u001b[39m loss_fn(predictions[:,\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mview(targets2\u001b[39m.\u001b[39msize), targets2)\n",
      "File \u001b[0;32m/apps/local/shared/HC701/hc701_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb Cell 10\u001b[0m in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m#encoding\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mfor\u001b[39;00m layers \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     x \u001b[39m=\u001b[39m layers(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m#skip connection to be used in recreation \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     skip_connections\u001b[39m.\u001b[39mappend(x)\n",
      "File \u001b[0;32m/apps/local/shared/HC701/hc701_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb Cell 10\u001b[0m in \u001b[0;36mConsecutiveConvolution.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.127.30.43/home/ning.sun/Documents/HC701/assignment/HC701/ass3/assignment3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x)\n",
      "File \u001b[0;32m/apps/local/shared/HC701/hc701_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/apps/local/shared/HC701/hc701_env/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/apps/local/shared/HC701/hc701_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/apps/local/shared/HC701/hc701_env/lib/python3.8/site-packages/torch/nn/modules/conv.py:443\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 443\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/apps/local/shared/HC701/hc701_env/lib/python3.8/site-packages/torch/nn/modules/conv.py:439\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    437\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    438\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 439\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    440\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 23.64 GiB total capacity; 4.71 GiB already allocated; 52.81 MiB free; 4.74 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "train_transform = A.Compose(\n",
    "        [\n",
    "            A.Resize(height=img_h, width=img_w),\n",
    "            A.Rotate(limit=35, p=1.0),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "#             A.VerticalFlip(p=0.1),\n",
    "            A.Normalize(\n",
    "                mean=[0.0, 0.0, 0.0],\n",
    "                std=[1.0, 1.0, 1.0],\n",
    "                max_pixel_value=255.0,\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "val_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=img_h, width=img_w),\n",
    "        A.Normalize(\n",
    "            mean=[0.0, 0.0, 0.0],\n",
    "            std=[1.0, 1.0, 1.0],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "model = UNet(input_channel=3, output_channel=2).to(dev)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_loader, val_loader,test_loader = get_loaders(\n",
    "    train_data,\n",
    "    test_data,\n",
    "    data_root,\n",
    "    batch_size,\n",
    "    train_transform,\n",
    "    val_transforms,\n",
    "    workers,\n",
    "    pin_mem,\n",
    ")\n",
    "\n",
    "# if LOAD_MODEL:\n",
    "#     load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model)\n",
    "exp_num = 1\n",
    "wandb.init(project=f\"hc_assign3_exp{exp_num}\", config={\"learning_rate\":lr})\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
    "\n",
    "    # save model\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\":optimizer.state_dict(),\n",
    "    }\n",
    "    save_checkpoint(checkpoint,filename=f'exp{exp_num}/{epoch}.pth.tar')\n",
    "\n",
    "    # check accuracy\n",
    "    val_fn(val_loader, model, device=dev,epoch=epoch)\n",
    "    test_fn(test_loader,model,device=dev,epoch=epoch)\n",
    "\n",
    "    # print some examples to a folder\n",
    "    # save_predictions_as_imgs(val_loader, model, folder=\"saved_images/\", device=dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-screw",
   "metadata": {
    "papermill": {
     "duration": 0.221334,
     "end_time": "2021-04-06T13:23:25.891427",
     "exception": false,
     "start_time": "2021-04-06T13:23:25.670093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "References: \n",
    "\n",
    "https://paperswithcode.com/paper/u-net-convolutional-networks-for-biomedical\n",
    "\n",
    "\n",
    "https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/image_segmentation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f372d41f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1947.884009,
   "end_time": "2021-04-06T13:23:28.655243",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-06T12:51:00.771234",
   "version": "2.3.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e3260d559458a8e05d43c32f2810d4489848f826459f2ace48b968ae1c4852b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
